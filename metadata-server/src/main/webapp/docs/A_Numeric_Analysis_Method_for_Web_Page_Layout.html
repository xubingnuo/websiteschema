<!--
To change this template, choose Tools | Templates
and open the template in the editor.
-->
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
    <head>
        <title>A Numeric Analysis Method for Web Page Layout</title>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <link rel="stylesheet" type="text/css" href="../style/book.css">
    </head>
    <body>
        <h3>网页布局的数值化分析方法与自动信息抽取</h3>
        <p>　　这是我在2009年写的一篇文章，实际情况是未完成的，因为实验部分实在是没有时间很好的完善，而且新颖的地方并不多，基本的方法是遵循RoadRunner和Webstemmer演变来的。但是这基本代表了Websiteschema的基本思想，是Websiteschema的雏型。</p>
        <div class="quote">
            <center id="paper-title"><h3>网页布局的数值化分析方法与自动信息抽取</h3></center>
            <p><b>摘要：</b><span id="abstract">综合目前对信息抽取技术的分析，本文借鉴在搜索引擎中，将文档集转换成向量空间的思路上，提出将网页布局数值化的方法，用以实现网页信息抽取的自动化。在本文构建的向量空间中，DOM树中的每一个XPath就是一个维度。通过构建向量空间，并为相同网站的不同页面进行聚类，通过聚类分析出相似的网页，然后采用目前一些已经较为成熟的方法，实现自动化抽取。本文介绍了网页布局的数值化方法，实现了对网易新闻的聚类分析，以及介绍了一个在此基础之上的信息抽取系统的简单实现。通过比较实验结果，证明了基于网页布局的向量空间，为实现无监督的机器学习提供了基本、有效的分析数据。另外作者认为其更重要的一个作用，是提示了大家不能忽略对目标网站页面类型的分析，其应该成为信息抽取的基本步骤，处于信息抽取的预处理环节中。</span></p>
            <p><b>关键词：</b><span id="keywords"><b>Web信息抽取</b>，<b>网页布局</b>，<b>聚类</b></span></p>
        </div>
        <p>　　当时因为RoadRunner需要选择语料，所以Webstemmer就将选择语料这一步都省略了，通过聚类来自动发现新闻网页。但是webstemmer的计算方法速度相对较慢，且聚类结果一旦扩展到其他类型的网站，则难以获得很好的效果。于是萌生了改进Webstemmer聚类算法的想法。</p>
        <div class="quote">
            <p>　　本文主要提出一种为页面布局数值化的方法，达到为网页进行聚类分析的目的，从而为进一步进行信息抽取提供有利的指导，本文主要讨论布局数值化的方法，并简单介绍一些在此基础上实现信息抽取的应用实现。</p>
        </div>
        <p>　　那么为什么要对网页首先进行聚类呢，是根据什么进行聚类呢？</p>
        <div class="quote">
            <p>　　目前网页信息抽取方法的情况，Hu[2]等人指出主要有基于DOM树和可视化Block两种研究方向，同时两种方法都互有一定的局限。基于DOM树的方法主要因为HTML的语法弹性很大，标签的语义信息很难明确[3]。同时基于Block的方法在作信息抽取的时候，很多有用的信息并非出现在明显的位置，以至于无法轻易的找到包含有用信息的Block[2]。在早些的论文[4]也指出，网页内容的抽取工作主要有几个共同的特点：</p>
            <ol>
                <li>要么需要预先人工标定的学习样本</li>
                <li>要么需要大量的先验知识</li>
                <li>一个时刻只能处理一个页面</li>
            </ol>
            <p>　　文献[2][4]中都指出：在内容丰富的网站中，大部分页面都可能通过后台数据库、脚本或程序发布，并提出了通过比较相似结构的文档，生成抽取器的方法。根据观察，即使是一个较大的新闻网站，其页面模板的数量也并不多，如果我们能够自动的归纳出网站上页面所属的类别，那么通过一些成熟的方法，可以更快捷的实现自动化抓取。</p>
            <p>　　文献[6]的作者提出了一个非常实用的方法，并称为Webstemmer，并由文献[7]为Webstemmer总结并指出了Webstemmer适用的前提条件：</p>
            <ol>
                <li>大多数网页都有共同的布局结构</li>
                <li>页面中主要文本的位置固定</li>
                <li>即使文本中的内容变化，页面的结构不变</li>
                <li>页面中的广告、导航等信息常常不变</li>
            </ol>
            <p>　　Webstemmer设计的无监督聚类分析方法，很好的解决了为网站进行自动聚类分析的问题，为文献[4]中需要人工指定学习类别，实现了自动化的方法。</p>
            <p>　　Webstemmer为实现无监督的网页抽取，取得了很大的成功。但实际使用中，Webstemmer仍然有一些限制和不足。例如在聚类和分类的上有一定的性能问题；相似性计算的算法太过简单，不适合复杂的Web页面；不便于管理和调整；对页面布局过于敏感；正是这些问题催生了对Webstemmer算法进行修改的愿望。</p>
        </div>
        <p>　　我们提出按照网页的布局对同一网站内的页面进行聚类，这和Webstemmer的想法是一致的，但是我们改进了其聚类算法。</p>
        <div class="quote">
            <p>　　本文拟提出将HTML页面分解为由绝对XPath代表的单元，构建以绝对XPath为轴的，描述HTML文档结构的向量空间。通过使用余弦度量的方法确定向量之间的相似度，最终实现对不同页面相同结构的分析。</p>
            <p>　　考虑在同一个页面中，文章的结构可以考虑成如图1所示的标签的序列。标签的序列由左至右变为XPath的序列，再添加属性信息，最后变成一个n维的向量。</p>
            <div class="figure"><img src="/docs/i/drawing_sO8ffHU0Y5aGnURyn3kuYsw_91.png" alt=""><br/><font size="-1">图1：HTML Tag、XPath、维度之间的转换</font></div>
            <p>　　可以简单的认识到，一定程度上，简单标签的序列看起来就已经可以代表了HTML页面的结构。参考Webstemmer的设计，本文选用XPath作为这个序列的Items，同时假定XPath描述的位置和其节点在页面上的位置相关。因为经过观察，相同XPath的节点，其在页面上出现的位置也大致相当。</p>
            <p>　　事实上，由于HTML语言本身的语法弹性太大，还需要在XPath中加上部分属性才能更好的使Xpath具有代表性。<b>这里提出一个假设：在同一个网站内，带有属性信息的绝对路径 (XPath)，和页面上拥有不同语义信息的标签，具有一一对应关系。</b>通过实践测试，使用align、font、class、id等几个分别代表位置、语义特征和外形的属性保存在XPath中即可。</p>
        </div>
        <p>　　通过第一个假设，并利用XPath的唯一性，将一篇文档，转换成一个向量。但是并没有提及如何得到向量上每一个维度的值如何计算，接下来就介绍了怎么统计每一个维度的权重，而这个权重就代表了每一个维度的值。</p>
        <div class="quote">
            <p>　　在将文章分解为由XPath组成的序列之后，我们就可以对两篇文章进行简单的比较了，如果两篇文章中XPath序列一致，那么这两篇文章必然是相同结构的。如果XPath序列相似，那么两篇文章也有可能是相同结构的。</p>
            <p>　　似乎这是一个很好的办法，但是如果这样，同一网站的视频新闻和普通新闻就有可能会因为具有相同的广告，而被认为是相同结构的，在某些特定的要求下，这是不愿意接受的。</p>
            <p>　　在Webstemmer中也提到了权重的概念，但其只是介绍了两篇文章相似度计算的方法。本文继续借鉴这种思想，但与Webstemmer不同。因为本文提出的方法首先以XPath为轴，构建了一个向量空间，从整个网站的大局来考虑。这样在程序设计上更加简单，对页面布局多样、负责的特点，也有较好的适应性。</p>
            <p>　　<b>本文提出的第二个假设：传递信息越多的标签，权重越大。</b>简单的说，标签中包含的平均文本数越多，权重越大。在这里，权重表示的是在向量空间中，处于某一维度的位置。</p>
            <p>　　在实际操作中，首先采集一定数量的页面，成为样本页面，将每个页面解析为以XPath为坐标，以该XPath包含文本数量为值的向量。</p>
            <p>　　在由这些向量构成的向量空间中，我们通过统计采集的样本，计算出每个XPath拥有的平均权重，形成权向量W。这里的平均权重，其实也是一个期望的概念。</p>
            <div class="figure"><img src="/docs/i/drawing_sTo9xnpFCBdYh36X1TJIqVw_166.png" alt=""><br/><font size="-1">图2：各维度权重的统计</font></div>
        </div>
        <p>　　现在我们知道了一篇文章可以被根据其包含的XPath被转换成一个向量，这个向量的每一个维度就是一个XPath，每个维度内的值就是统计出来的平均权重。下面还举例说明了一下相似度计算：</p>
        <div class="quote">
            <p>　　任何页面，只要拥有样本集里面的任意一条XPath，那么这个页面就在这个XPath代表的维度上，使用经过统计之后得到的权值Wi，做为该页面在这一维度的特征值。通过对样本页面使用这样的方法重新计算，得到若干向量，最后通过余弦度量的方法[3]，计算样本页面中每个页面的结构相似度了。</p>
            <p>　　如果两个向量之间，同时包含一些最主要的维度，表明他们之间在几个权重较大的维度上拥有相同的值，其夹角变小，所以两个向量也就更相似了，体现了权重的作用。</p>
            <p>　　在下图所示，快讯频道可能没有正文，这两个页面即使别的标签都一样，但因为正文的标签不同，所以两个页面之间差别仍会很大。</p>
            <div class="figure"><img src="/docs/i/drawing_seYVGMBszVL_h7bSEZqiwMQ_154.png" alt=""><br/><font size="-1">图2：各维度权重的统计</font></div>
            <p>　　通过构建相似矩阵，可以实现聚类分析，分别得到几个类别的样本点。今后采集到新的页面，只要将其转换为向量空间中的一个点 (其中每个维度的值仍然使用统计之后的平均权重)，就可以计算出它属于那个类别了。</p>
        </div>
        <p>　　其实只要构建了向量空间，就可以使用更通用的方法去进行聚类了，可以使用基于距离的计算方法，也可以使用基于相似度的计算方法。</p>
        <h3>小结</h3>
        <p>　　这种方法可以帮助我们对网站内的网页进行分类，但不能解决全部的问题，并且这篇文章提出的一些假设，只是在大多数情况下适用。真实世界中不同网页之间的差异性，残酷的打破了希望以统一的方法对信息进行抽取的美梦。</p>
        <center><a href="web_information_extraction.html">返回</a></center>
    </body>
</html>
